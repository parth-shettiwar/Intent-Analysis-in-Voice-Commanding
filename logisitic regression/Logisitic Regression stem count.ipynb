{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTENT</th>\n",
       "      <th>ID</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please clear the italics sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stop dictation near the last paragraph</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left align the first word of selected paragraph</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clear bold for last two sentences</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insert comment on the selected line</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            INTENT  ID Unnamed: 2\n",
       "0                Please clear the italics sentence   5        NaN\n",
       "1           Stop dictation near the last paragraph  23        NaN\n",
       "2  left align the first word of selected paragraph  16        NaN\n",
       "3                clear bold for last two sentences   3        NaN\n",
       "4              insert comment on the selected line  15        NaN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel (r'C:\\Users\\HP\\Downloads\\Dataset.xlsx')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>INTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Please clear the italics sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Stop dictation near the last paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>left align the first word of selected paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>clear bold for last two sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>insert comment on the selected line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           INTENT\n",
       "0   5                Please clear the italics sentence\n",
       "1  23           Stop dictation near the last paragraph\n",
       "2  16  left align the first word of selected paragraph\n",
       "3   3                clear bold for last two sentences\n",
       "4  15              insert comment on the selected line"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df) \n",
    "df.drop(['Unnamed: 2'], axis=1)\n",
    "df.dropna(subset=['INTENT'], inplace=True)\n",
    "df = df[['ID', 'INTENT']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>INTENT</th>\n",
       "      <th>intent_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Please clear the italics sentence</td>\n",
       "      <td>[please, clear, the, italics, sentence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Stop dictation near the last paragraph</td>\n",
       "      <td>[stop, dictation, near, the, last, paragraph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>left align the first word of selected paragraph</td>\n",
       "      <td>[left, align, the, first, word, of, selected, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>clear bold for last two sentences</td>\n",
       "      <td>[clear, bold, for, last, two, sentences]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>insert comment on the selected line</td>\n",
       "      <td>[insert, comment, on, the, selected, line]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           INTENT  \\\n",
       "0   5                Please clear the italics sentence   \n",
       "1  23           Stop dictation near the last paragraph   \n",
       "2  16  left align the first word of selected paragraph   \n",
       "3   3                clear bold for last two sentences   \n",
       "4  15              insert comment on the selected line   \n",
       "\n",
       "                                    intent_tokenized  \n",
       "0            [please, clear, the, italics, sentence]  \n",
       "1      [stop, dictation, near, the, last, paragraph]  \n",
       "2  [left, align, the, first, word, of, selected, ...  \n",
       "3           [clear, bold, for, last, two, sentences]  \n",
       "4         [insert, comment, on, the, selected, line]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens=re.split('\\W+',text)\n",
    "    return tokens\n",
    "df['intent_tokenized']=df['INTENT'].apply(lambda x:tokenize(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>INTENT</th>\n",
       "      <th>intent_tokenized</th>\n",
       "      <th>intent_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Please clear the italics sentence</td>\n",
       "      <td>[please, clear, the, italics, sentence]</td>\n",
       "      <td>[clear, italics, sentence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Stop dictation near the last paragraph</td>\n",
       "      <td>[stop, dictation, near, the, last, paragraph]</td>\n",
       "      <td>[stop, dictation, near, last, paragraph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>left align the first word of selected paragraph</td>\n",
       "      <td>[left, align, the, first, word, of, selected, ...</td>\n",
       "      <td>[left, align, first, word, selected, paragraph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>clear bold for last two sentences</td>\n",
       "      <td>[clear, bold, for, last, two, sentences]</td>\n",
       "      <td>[clear, bold, last, two, sentences]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>insert comment on the selected line</td>\n",
       "      <td>[insert, comment, on, the, selected, line]</td>\n",
       "      <td>[insert, comment, selected, line]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           INTENT  \\\n",
       "0   5                Please clear the italics sentence   \n",
       "1  23           Stop dictation near the last paragraph   \n",
       "2  16  left align the first word of selected paragraph   \n",
       "3   3                clear bold for last two sentences   \n",
       "4  15              insert comment on the selected line   \n",
       "\n",
       "                                    intent_tokenized  \\\n",
       "0            [please, clear, the, italics, sentence]   \n",
       "1      [stop, dictation, near, the, last, paragraph]   \n",
       "2  [left, align, the, first, word, of, selected, ...   \n",
       "3           [clear, bold, for, last, two, sentences]   \n",
       "4         [insert, comment, on, the, selected, line]   \n",
       "\n",
       "                                     intent_nostop  \n",
       "0                       [clear, italics, sentence]  \n",
       "1         [stop, dictation, near, last, paragraph]  \n",
       "2  [left, align, first, word, selected, paragraph]  \n",
       "3              [clear, bold, last, two, sentences]  \n",
       "4                [insert, comment, selected, line]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#stopword=nltk.download('stopwords')\n",
    "stopword=nltk.corpus.stopwords.words('english')\n",
    "stopword.append(\"please\")\n",
    "stopword.append(\"could\")\n",
    "stopword.append(\"need\")\n",
    "stopword.append(\" \")\n",
    "stopword.append(\"kindly\")\n",
    "def remove_stopword(tokenised_list):\n",
    "    text=[word for word in tokenised_list if word not in stopword]\n",
    "    return text\n",
    "df['intent_nostop']=df['intent_tokenized'].apply(lambda x:remove_stopword(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>INTENT</th>\n",
       "      <th>intent_tokenized</th>\n",
       "      <th>intent_nostop</th>\n",
       "      <th>intent_nostop_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Please clear the italics sentence</td>\n",
       "      <td>[please, clear, the, italics, sentence]</td>\n",
       "      <td>[clear, italics, sentence]</td>\n",
       "      <td>[clear, ital, sentenc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Stop dictation near the last paragraph</td>\n",
       "      <td>[stop, dictation, near, the, last, paragraph]</td>\n",
       "      <td>[stop, dictation, near, last, paragraph]</td>\n",
       "      <td>[stop, dictat, near, last, paragraph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>left align the first word of selected paragraph</td>\n",
       "      <td>[left, align, the, first, word, of, selected, ...</td>\n",
       "      <td>[left, align, first, word, selected, paragraph]</td>\n",
       "      <td>[left, align, first, word, select, paragraph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>clear bold for last two sentences</td>\n",
       "      <td>[clear, bold, for, last, two, sentences]</td>\n",
       "      <td>[clear, bold, last, two, sentences]</td>\n",
       "      <td>[clear, bold, last, two, sentenc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>insert comment on the selected line</td>\n",
       "      <td>[insert, comment, on, the, selected, line]</td>\n",
       "      <td>[insert, comment, selected, line]</td>\n",
       "      <td>[insert, comment, select, line]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           INTENT  \\\n",
       "0   5                Please clear the italics sentence   \n",
       "1  23           Stop dictation near the last paragraph   \n",
       "2  16  left align the first word of selected paragraph   \n",
       "3   3                clear bold for last two sentences   \n",
       "4  15              insert comment on the selected line   \n",
       "\n",
       "                                    intent_tokenized  \\\n",
       "0            [please, clear, the, italics, sentence]   \n",
       "1      [stop, dictation, near, the, last, paragraph]   \n",
       "2  [left, align, the, first, word, of, selected, ...   \n",
       "3           [clear, bold, for, last, two, sentences]   \n",
       "4         [insert, comment, on, the, selected, line]   \n",
       "\n",
       "                                     intent_nostop  \\\n",
       "0                       [clear, italics, sentence]   \n",
       "1         [stop, dictation, near, last, paragraph]   \n",
       "2  [left, align, first, word, selected, paragraph]   \n",
       "3              [clear, bold, last, two, sentences]   \n",
       "4                [insert, comment, selected, line]   \n",
       "\n",
       "                              intent_nostop_stem  \n",
       "0                         [clear, ital, sentenc]  \n",
       "1          [stop, dictat, near, last, paragraph]  \n",
       "2  [left, align, first, word, select, paragraph]  \n",
       "3              [clear, bold, last, two, sentenc]  \n",
       "4                [insert, comment, select, line]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps=nltk.PorterStemmer()\n",
    "def stemming(tokenised_list):\n",
    "    text=[ps.stem(word) for word in tokenised_list ]\n",
    "    return text\n",
    "df['intent_nostop_stem']=df['intent_nostop'].apply(lambda x:stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>INTENT</th>\n",
       "      <th>intent_tokenized</th>\n",
       "      <th>intent_nostop</th>\n",
       "      <th>intent_nostop_stem</th>\n",
       "      <th>intent_nostop_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Please clear the italics sentence</td>\n",
       "      <td>[please, clear, the, italics, sentence]</td>\n",
       "      <td>[clear, italics, sentence]</td>\n",
       "      <td>[clear, ital, sentenc]</td>\n",
       "      <td>[clear, italic, sentence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Stop dictation near the last paragraph</td>\n",
       "      <td>[stop, dictation, near, the, last, paragraph]</td>\n",
       "      <td>[stop, dictation, near, last, paragraph]</td>\n",
       "      <td>[stop, dictat, near, last, paragraph]</td>\n",
       "      <td>[stop, dictation, near, last, paragraph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>left align the first word of selected paragraph</td>\n",
       "      <td>[left, align, the, first, word, of, selected, ...</td>\n",
       "      <td>[left, align, first, word, selected, paragraph]</td>\n",
       "      <td>[left, align, first, word, select, paragraph]</td>\n",
       "      <td>[left, align, first, word, selected, paragraph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>clear bold for last two sentences</td>\n",
       "      <td>[clear, bold, for, last, two, sentences]</td>\n",
       "      <td>[clear, bold, last, two, sentences]</td>\n",
       "      <td>[clear, bold, last, two, sentenc]</td>\n",
       "      <td>[clear, bold, last, two, sentence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>insert comment on the selected line</td>\n",
       "      <td>[insert, comment, on, the, selected, line]</td>\n",
       "      <td>[insert, comment, selected, line]</td>\n",
       "      <td>[insert, comment, select, line]</td>\n",
       "      <td>[insert, comment, selected, line]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           INTENT  \\\n",
       "0   5                Please clear the italics sentence   \n",
       "1  23           Stop dictation near the last paragraph   \n",
       "2  16  left align the first word of selected paragraph   \n",
       "3   3                clear bold for last two sentences   \n",
       "4  15              insert comment on the selected line   \n",
       "\n",
       "                                    intent_tokenized  \\\n",
       "0            [please, clear, the, italics, sentence]   \n",
       "1      [stop, dictation, near, the, last, paragraph]   \n",
       "2  [left, align, the, first, word, of, selected, ...   \n",
       "3           [clear, bold, for, last, two, sentences]   \n",
       "4         [insert, comment, on, the, selected, line]   \n",
       "\n",
       "                                     intent_nostop  \\\n",
       "0                       [clear, italics, sentence]   \n",
       "1         [stop, dictation, near, last, paragraph]   \n",
       "2  [left, align, first, word, selected, paragraph]   \n",
       "3              [clear, bold, last, two, sentences]   \n",
       "4                [insert, comment, selected, line]   \n",
       "\n",
       "                              intent_nostop_stem  \\\n",
       "0                         [clear, ital, sentenc]   \n",
       "1          [stop, dictat, near, last, paragraph]   \n",
       "2  [left, align, first, word, select, paragraph]   \n",
       "3              [clear, bold, last, two, sentenc]   \n",
       "4                [insert, comment, select, line]   \n",
       "\n",
       "                                 intent_nostop_lem  \n",
       "0                        [clear, italic, sentence]  \n",
       "1         [stop, dictation, near, last, paragraph]  \n",
       "2  [left, align, first, word, selected, paragraph]  \n",
       "3               [clear, bold, last, two, sentence]  \n",
       "4                [insert, comment, selected, line]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "lm=nltk.WordNetLemmatizer()\n",
    "def lemmatizing(tokenised_list):\n",
    "    text=[lm.lemmatize(word) for word in tokenised_list ]\n",
    "    return text\n",
    "df['intent_nostop_lem']=df['intent_nostop'].apply(lambda x:lemmatizing(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_intent=[]\n",
    "def clean_text_stem(text):\n",
    "    tokens=re.split('\\W+',text)\n",
    "    [stopwords_intent.append(word) for word in tokens if word in stopword]\n",
    "    text=[ps.stem(word) for word in tokens if word not in stopword]\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 86)\n",
      "['', 'Go', 'add', 'align', 'bold', 'break', 'bullet', 'capit', 'centr', 'chang', 'charact', 'clear', 'color', 'command', 'comment', 'content', 'delet', 'dictat', 'display', 'end', 'eras', 'first', 'five', 'format', 'four', 'full', 'go', 'halt', 'help', 'icon', 'imag', 'insert', 'ital', 'italic', 'italicis', 'kindli', 'last', 'left', 'let', 'letter', 'line', 'list', 'make', 'middl', 'move', 'near', 'new', 'next', 'open', 'page', 'paragraph', 'paus', 'pictur', 'place', 'pleas', 'posit', 'present', 'previou', 'put', 'red', 'remov', 'requir', 'reveal', 'right', 'select', 'sentenc', 'shift', 'show', 'start', 'stop', 'strike', 'strikethrough', 'subscript', 'superscript', 'symbol', 'tabl', 'take', 'text', 'textoutlin', 'three', 'two', 'unbold', 'underlin', 'undo', 'unitalic', 'word']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect_stem=CountVectorizer(analyzer=clean_text_stem)\n",
    "X_counts_stem=count_vect_stem.fit_transform(df['INTENT'])\n",
    "print(X_counts_stem.shape)\n",
    "print(count_vect_stem.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7488ac522d33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_counts_stem_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_counts_stem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_counts_stem_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount_vect_stem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_counts_stem_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_counts_stem_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "X_counts_stem_df=pd.DataFrame(X_counts_stem.toarray())\n",
    "X_counts_stem_df.columns=count_vect_stem.get_feature_names()\n",
    "X_counts_stem_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Go</th>\n",
       "      <th>add</th>\n",
       "      <th>align</th>\n",
       "      <th>bold</th>\n",
       "      <th>break</th>\n",
       "      <th>bullet</th>\n",
       "      <th>capit</th>\n",
       "      <th>centr</th>\n",
       "      <th>chang</th>\n",
       "      <th>...</th>\n",
       "      <th>take</th>\n",
       "      <th>text</th>\n",
       "      <th>textoutlin</th>\n",
       "      <th>three</th>\n",
       "      <th>two</th>\n",
       "      <th>unbold</th>\n",
       "      <th>underlin</th>\n",
       "      <th>undo</th>\n",
       "      <th>unitalic</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Go  add  align  bold  break  bullet  capit  centr  chang  ...   take  \\\n",
       "0  0   0    0      0     0      0       0      0      0      0  ...      0   \n",
       "1  0   0    0      0     0      0       0      0      0      0  ...      0   \n",
       "2  0   0    0      1     0      0       0      0      0      0  ...      0   \n",
       "3  0   0    0      0     1      0       0      0      0      0  ...      0   \n",
       "4  0   0    0      0     0      0       0      0      0      0  ...      0   \n",
       "\n",
       "   text  textoutlin  three  two  unbold  underlin  undo  unitalic  word  \n",
       "0     0           0      0    0       0         0     0         0     0  \n",
       "1     0           0      0    0       0         0     0         0     0  \n",
       "2     0           0      0    0       0         0     0         0     1  \n",
       "3     0           0      0    1       0         0     0         0     0  \n",
       "4     0           0      0    0       0         0     0         0     0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features=X_counts_stem_df\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9931972789115646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, df['ID'], test_size=0.0, random_state=0)\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19157"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib \n",
    "import os\n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(clf, 'clf')\n",
    "os.path.getsize('clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from sklearn.model_selection import KFold, cross_val_score\n",
    "#k_fold=KFold(n_splits=10)\n",
    "#cross_val_score(clf,X_features,df['ID'],cv=k_fold,scoring='accuracy',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'the', 'the', 'of', 'for']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_intent[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           [clear, ital, sentenc]\n",
      "1            [stop, dictat, near, last, paragraph]\n",
      "2    [left, align, first, word, select, paragraph]\n",
      "3                [clear, bold, last, two, sentenc]\n",
      "4                  [insert, comment, select, line]\n",
      "Name: intent_nostop_stem, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"intent_nostop_stem\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_intent=[]\n",
    "all_token_intent=all_token_intent+[(lis) for lis in df[\"intent_nostop_stem\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['clear', 'ital', 'sentenc'], ['stop', 'dictat', 'near', 'last', 'paragraph'], ['left', 'align', 'first', 'word', 'select', 'paragraph'], ['clear', 'bold', 'last', 'two', 'sentenc'], ['insert', 'comment', 'select', 'line']]\n"
     ]
    }
   ],
   "source": [
    "print(all_token_intent[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in all_token_intent for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clear': 35, 'ital': 13, 'sentenc': 27, 'stop': 20, 'dictat': 36, 'near': 18, 'last': 108, 'paragraph': 39, 'left': 13, 'align': 43, 'first': 20, 'word': 73, 'select': 51, 'bold': 28, 'two': 40, 'insert': 25, 'comment': 15, 'line': 29, 'delet': 20, 'display': 7, 'list': 2, 'command': 21, 'posit': 3, 'imag': 6, 'middl': 5, 'page': 6, 'remov': 78, 'underlin': 41, 'format': 23, 'subscript': 32, 'text': 47, 'strikethrough': 32, '': 26, 'add': 5, 'open': 9, 'unbold': 6, 'help': 13, 'bullet': 38, 'undo': 18, 'chang': 5, 'start': 9, 'next': 12, 'superscript': 32, 'paus': 13, 'charact': 32, 'three': 7, 'centr': 17, 'make': 10, 'full': 1, 'italic': 7, 'previou': 1, 'go': 4, 'right': 19, 'tabl': 9, 'end': 10, 'content': 4, 'new': 2, 'eras': 3, 'unitalic': 4, 'place': 2, 'five': 1, 'show': 10, 'italicis': 4, 'move': 6, 'requir': 1, 'strike': 2, 'letter': 2, 'shift': 1, 'icon': 3, 'capit': 1, 'symbol': 1, 'take': 2, 'break': 2, 'halt': 3, 'present': 3, 'red': 1, 'color': 1, 'four': 1, 'reveal': 1, 'pleas': 1, 'pictur': 1, 'put': 2, 'let': 1, 'need': 1, 'textoutlin': 1}\n"
     ]
    }
   ],
   "source": [
    "freq={}\n",
    "def CountFrequency(my_list): \n",
    "    for item in my_list: \n",
    "        if (item in freq): \n",
    "            freq[item] += 1\n",
    "        else: \n",
    "            freq[item] = 1\n",
    "CountFrequency(flat_list)\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_test_pred = cross_val_predict(clf,X_train,y_train,cv=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 22,  8,  7,  2, 15,  6,  1,  5, 20, 11, 20, 25, 18,  1, 26,  2,\n",
       "       23, 18, 22, 17,  9, 24,  9, 11, 12,  4, 25,  9,  8, 13,  6, 23, 24,\n",
       "       13,  7, 26,  7,  6, 26, 24,  1,  6,  2, 17, 13,  6,  1, 23, 23, 24,\n",
       "       15, 25, 11, 17, 12,  3, 18,  7, 26, 14, 22, 11, 24,  9,  5, 21, 22,\n",
       "       10,  6, 11, 17, 13, 12, 17, 14, 22,  2, 15, 14,  1,  1,  6, 22, 10,\n",
       "       26,  4, 10,  4,  9,  2, 15,  2,  5, 15,  9, 12, 23,  2, 14, 16, 26,\n",
       "        3, 22, 21, 24, 13, 24, 15,  9,  8, 26,  3,  6, 12,  9,  7, 14,  8,\n",
       "        4, 18, 13, 16, 13, 18, 23, 23,  6, 25, 18,  9,  3, 21, 14, 18, 24,\n",
       "       22, 24, 15, 19,  2, 25, 11, 17, 17, 13, 26,  6, 14,  6, 16,  7, 26,\n",
       "       22,  7, 18, 24, 14, 20,  2,  5,  3, 15,  6,  3, 15, 10, 26, 18, 23,\n",
       "       15, 11,  4, 18,  7,  1, 13, 17, 26, 13, 26, 24, 17, 11, 15, 18, 18,\n",
       "        2, 19, 16,  7, 21, 26,  5,  4,  6, 26, 14, 26,  6, 14, 13, 18, 18,\n",
       "       14, 21,  5, 15,  4, 14, 16, 10, 26,  5, 23,  8, 23, 21,  5, 18,  1,\n",
       "       19, 17,  2, 11,  6,  3, 26, 23, 11, 16,  1,  1, 22, 19, 13,  3, 19,\n",
       "        9, 10, 10, 12,  1,  8, 25,  6, 22,  8,  4, 19, 18, 12, 20,  8,  3,\n",
       "        1, 24, 11,  7, 10, 17,  4, 13, 22, 21,  2, 24, 26,  1,  9, 23, 14,\n",
       "       16, 15, 12,  3,  5, 10,  6, 10, 12, 11, 16, 14, 25, 11, 21,  7, 26,\n",
       "       24,  8,  8, 23,  3, 20,  9,  3, 14, 21,  3,  4, 17, 25,  2, 19, 23,\n",
       "        6, 13,  5,  1, 10, 17, 26, 17, 24,  6, 20, 26,  9, 13, 24, 10, 10,\n",
       "       18,  6, 16,  4, 21, 16, 12, 24, 23,  5, 10,  1, 14, 19, 22, 13,  6,\n",
       "       23, 13, 11, 25, 18,  3, 18, 18,  5,  6, 14, 16, 24,  5, 26,  9, 17,\n",
       "       26, 24, 25, 14, 25, 14, 23,  8,  9,  1, 13,  2, 24, 11,  1,  2, 18,\n",
       "       21, 10, 18, 10,  8, 14, 21,  5, 22, 22, 23,  3, 19, 17,  7, 19, 25,\n",
       "       18, 13, 20,  8,  5,  9, 14, 20, 22, 21, 19, 19,  6,  6,  2,  7, 16,\n",
       "        2,  6, 15,  8, 15,  8, 10, 25,  3, 13, 13, 13,  8,  1,  5, 22,  6,\n",
       "       19, 20,  5, 17,  7, 20, 22,  7, 17, 17, 20, 13, 20, 24, 12,  3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "for i in y_train.index:\n",
    "    x.append(df.iloc[i][\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 22,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 15,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 20,\n",
       " 11,\n",
       " 20,\n",
       " 25,\n",
       " 18,\n",
       " 1,\n",
       " 26,\n",
       " 2,\n",
       " 23,\n",
       " 18,\n",
       " 22,\n",
       " 17,\n",
       " 9,\n",
       " 24,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 4,\n",
       " 25,\n",
       " 9,\n",
       " 8,\n",
       " 13,\n",
       " 6,\n",
       " 23,\n",
       " 24,\n",
       " 13,\n",
       " 7,\n",
       " 26,\n",
       " 7,\n",
       " 6,\n",
       " 26,\n",
       " 24,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 17,\n",
       " 13,\n",
       " 6,\n",
       " 1,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 15,\n",
       " 25,\n",
       " 11,\n",
       " 17,\n",
       " 12,\n",
       " 3,\n",
       " 18,\n",
       " 7,\n",
       " 26,\n",
       " 14,\n",
       " 22,\n",
       " 11,\n",
       " 24,\n",
       " 9,\n",
       " 5,\n",
       " 21,\n",
       " 22,\n",
       " 10,\n",
       " 6,\n",
       " 11,\n",
       " 17,\n",
       " 13,\n",
       " 12,\n",
       " 17,\n",
       " 14,\n",
       " 22,\n",
       " 2,\n",
       " 15,\n",
       " 14,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 22,\n",
       " 10,\n",
       " 26,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 15,\n",
       " 2,\n",
       " 5,\n",
       " 15,\n",
       " 9,\n",
       " 12,\n",
       " 23,\n",
       " 2,\n",
       " 14,\n",
       " 16,\n",
       " 26,\n",
       " 3,\n",
       " 22,\n",
       " 21,\n",
       " 24,\n",
       " 13,\n",
       " 24,\n",
       " 15,\n",
       " 9,\n",
       " 8,\n",
       " 26,\n",
       " 3,\n",
       " 6,\n",
       " 12,\n",
       " 9,\n",
       " 7,\n",
       " 14,\n",
       " 8,\n",
       " 4,\n",
       " 18,\n",
       " 13,\n",
       " 16,\n",
       " 13,\n",
       " 18,\n",
       " 23,\n",
       " 23,\n",
       " 7,\n",
       " 25,\n",
       " 18,\n",
       " 9,\n",
       " 3,\n",
       " 21,\n",
       " 14,\n",
       " 18,\n",
       " 24,\n",
       " 22,\n",
       " 24,\n",
       " 15,\n",
       " 19,\n",
       " 2,\n",
       " 25,\n",
       " 11,\n",
       " 17,\n",
       " 17,\n",
       " 13,\n",
       " 26,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 16,\n",
       " 7,\n",
       " 26,\n",
       " 22,\n",
       " 7,\n",
       " 18,\n",
       " 24,\n",
       " 14,\n",
       " 20,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 15,\n",
       " 6,\n",
       " 3,\n",
       " 15,\n",
       " 10,\n",
       " 26,\n",
       " 18,\n",
       " 23,\n",
       " 15,\n",
       " 11,\n",
       " 4,\n",
       " 18,\n",
       " 7,\n",
       " 1,\n",
       " 13,\n",
       " 17,\n",
       " 26,\n",
       " 13,\n",
       " 26,\n",
       " 24,\n",
       " 17,\n",
       " 11,\n",
       " 15,\n",
       " 18,\n",
       " 18,\n",
       " 2,\n",
       " 19,\n",
       " 16,\n",
       " 7,\n",
       " 21,\n",
       " 26,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 26,\n",
       " 14,\n",
       " 26,\n",
       " 6,\n",
       " 14,\n",
       " 13,\n",
       " 18,\n",
       " 18,\n",
       " 14,\n",
       " 19,\n",
       " 5,\n",
       " 15,\n",
       " 4,\n",
       " 14,\n",
       " 16,\n",
       " 10,\n",
       " 26,\n",
       " 5,\n",
       " 23,\n",
       " 8,\n",
       " 23,\n",
       " 21,\n",
       " 4,\n",
       " 18,\n",
       " 1,\n",
       " 19,\n",
       " 17,\n",
       " 2,\n",
       " 11,\n",
       " 6,\n",
       " 3,\n",
       " 26,\n",
       " 23,\n",
       " 11,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 22,\n",
       " 19,\n",
       " 13,\n",
       " 3,\n",
       " 19,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 1,\n",
       " 8,\n",
       " 25,\n",
       " 6,\n",
       " 22,\n",
       " 8,\n",
       " 4,\n",
       " 19,\n",
       " 18,\n",
       " 12,\n",
       " 20,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 24,\n",
       " 11,\n",
       " 7,\n",
       " 10,\n",
       " 17,\n",
       " 4,\n",
       " 13,\n",
       " 22,\n",
       " 21,\n",
       " 2,\n",
       " 24,\n",
       " 26,\n",
       " 1,\n",
       " 9,\n",
       " 23,\n",
       " 14,\n",
       " 16,\n",
       " 15,\n",
       " 12,\n",
       " 3,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 12,\n",
       " 11,\n",
       " 16,\n",
       " 14,\n",
       " 25,\n",
       " 11,\n",
       " 19,\n",
       " 7,\n",
       " 26,\n",
       " 24,\n",
       " 8,\n",
       " 8,\n",
       " 23,\n",
       " 3,\n",
       " 20,\n",
       " 9,\n",
       " 3,\n",
       " 14,\n",
       " 21,\n",
       " 3,\n",
       " 4,\n",
       " 17,\n",
       " 25,\n",
       " 2,\n",
       " 19,\n",
       " 23,\n",
       " 6,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 10,\n",
       " 17,\n",
       " 26,\n",
       " 17,\n",
       " 24,\n",
       " 6,\n",
       " 20,\n",
       " 26,\n",
       " 9,\n",
       " 12,\n",
       " 24,\n",
       " 10,\n",
       " 10,\n",
       " 18,\n",
       " 6,\n",
       " 16,\n",
       " 4,\n",
       " 21,\n",
       " 16,\n",
       " 12,\n",
       " 24,\n",
       " 23,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 14,\n",
       " 19,\n",
       " 22,\n",
       " 13,\n",
       " 6,\n",
       " 23,\n",
       " 12,\n",
       " 11,\n",
       " 25,\n",
       " 18,\n",
       " 3,\n",
       " 18,\n",
       " 18,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 16,\n",
       " 24,\n",
       " 5,\n",
       " 26,\n",
       " 9,\n",
       " 17,\n",
       " 26,\n",
       " 24,\n",
       " 25,\n",
       " 14,\n",
       " 25,\n",
       " 14,\n",
       " 23,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 24,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 18,\n",
       " 21,\n",
       " 10,\n",
       " 18,\n",
       " 10,\n",
       " 8,\n",
       " 14,\n",
       " 21,\n",
       " 5,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 3,\n",
       " 19,\n",
       " 17,\n",
       " 7,\n",
       " 19,\n",
       " 25,\n",
       " 18,\n",
       " 13,\n",
       " 20,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 14,\n",
       " 20,\n",
       " 22,\n",
       " 21,\n",
       " 19,\n",
       " 19,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 16,\n",
       " 2,\n",
       " 6,\n",
       " 15,\n",
       " 8,\n",
       " 15,\n",
       " 8,\n",
       " 10,\n",
       " 25,\n",
       " 3,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 22,\n",
       " 6,\n",
       " 21,\n",
       " 20,\n",
       " 5,\n",
       " 17,\n",
       " 7,\n",
       " 20,\n",
       " 22,\n",
       " 7,\n",
       " 17,\n",
       " 17,\n",
       " 20,\n",
       " 13,\n",
       " 20,\n",
       " 24,\n",
       " 12,\n",
       " 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) confused between remove or apply\n",
    "2) some remove sentences have undo like undo strikethrough it is taking simple undo under that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "labels=[]\n",
    "for i in range(1,27):\n",
    "    labels.append(i)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  2 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 11  2  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  2  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 11  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      0.79      0.88        14\n",
      "           5       0.82      1.00      0.90        14\n",
      "           6       0.92      1.00      0.96        24\n",
      "           7       1.00      0.88      0.94        17\n",
      "           8       1.00      1.00      1.00        16\n",
      "           9       1.00      1.00      1.00        16\n",
      "          10       1.00      1.00      1.00        17\n",
      "          11       1.00      1.00      1.00        15\n",
      "          12       1.00      0.85      0.92        13\n",
      "          13       0.91      1.00      0.95        21\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       1.00      1.00      1.00        15\n",
      "          16       1.00      1.00      1.00        13\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        23\n",
      "          19       0.92      0.86      0.89        14\n",
      "          20       1.00      1.00      1.00        12\n",
      "          21       0.85      0.92      0.88        12\n",
      "          22       1.00      1.00      1.00        18\n",
      "          23       1.00      1.00      1.00        18\n",
      "          24       1.00      1.00      1.00        21\n",
      "          25       1.00      1.00      1.00        13\n",
      "          26       1.00      1.00      1.00        23\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       441\n",
      "   macro avg       0.98      0.97      0.97       441\n",
      "weighted avg       0.98      0.98      0.98       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(x, y_test_pred, labels=labels))\n",
    "print(metrics.classification_report(x, y_test_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_intent_map={1:\"undo\",2:\"bold\",3:\"unbold\",4:\"italics\",5:\"unitalics\",6:\"underline\",7:\"un-underline\",8:\"superscript\",9:\"un-superscript\",10:\"subscript\",11:\"un-subscript\",12:\"strike\",13:\"unstrike\",14:\"center align\",15:\"comment\",16:\"left align\",17:\"right align\",18:\"un-format\",19:\"insert bullet\",20:\"next bullet\",21:\"end bullet\",22:\"pause dictation\",23:\"stop dictation\",24:\"commands\",25:\"help\",26:\"delete\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end bullet'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input={'str':[\"exit bullets\"]}\n",
    "x_df = pd.DataFrame(input)\n",
    "x_str=count_vect_stem.transform(x_df['str'])\n",
    "x_str_stem_df=pd.DataFrame(x_str.toarray())\n",
    "x_str_stem_df.columns=count_vect_stem.get_feature_names()\n",
    "y_str=clf.predict(x_str_stem_df)\n",
    "id_intent_map[y_str[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_porter import Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Currently the given estimator 'LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)' isn't supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ba54eb9f85c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mporter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'java'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn_porter\\Porter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, estimator, language, method, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Currently the given estimator '{estimator}' isn't\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[1;34m\" supported.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m# Import estimator class:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Currently the given estimator 'LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)' isn't supported."
     ]
    }
   ],
   "source": [
    "porter = Porter(clf, language='java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
